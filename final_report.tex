\documentclass[11pt,
  a4paper,
  ngerman,
  BCOR=7mm
]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{tocbasic}
\usepackage[headsepline]{scrpage2}
\usepackage[german]{fancyref}
\usepackage{xcolor}
\usepackage[hyphens]{url}
\usepackage{listings}
\usepackage[pdftex]{graphicx}
\usepackage{courier}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage[colorlinks=false, linktocpage]{hyperref}
\setlength\parindent{0pt} 

\usepackage{DejaVuSansMono}
\lstset{language=C}
\lstset{basicstyle=\footnotesize\ttfamily}
\lstset{breaklines=true}
\lstset{keywordstyle=\color{purple}}
\lstset{showstringspaces=false}

\usepackage{geometry}
\usepackage{tikz}
\usetikzlibrary{calc,arrows}

\newdimen\XCoord
\newdimen\YCoord

\newcommand*{\ExtractCoordinate}[1]{\path (#1); \pgfgetlastxy{\XCoord}{\YCoord};}%

\usepackage{url}

\author{Michael Krause, Robin Nehls, Jakob Pfender}
\title{Softwareprojekt Mobilkommunikation:\\Gossiping on Mobile
Devices\\Final Project Report}

\begin{document}

\maketitle

\newpage

\section*{Overview and Motivation}
\label{sec:overview_motivation}
Our task was to implement gossiping for RIOT on an application level,
such that it could ideally be used as a platform for any number of
applications that can benefit from information dissemination via
gossiping. Therefore, our overarching goal was to implement the
gossiping architecture in as modular a way as possible so that arbitrary
``plug-in`` applications could use it to share their information among
participating nodes. This approach would also enable us to hand over the
completed code to the RIOT project after the software project ended in
order to provide them with a generic gossiping platform upon which
further applications can be built. In the following report, we will
examine our work on this project and assess whether all of our goals
have been met.

\section*{Three Phases}
\label{sec:three_phases}
As a way of structuring our development, we decided to divide our
project into three distinct phases, with each phase building on the
previous one. This allowed us to formulate clear milestones and also
resulted in our project being essentially composed of several smaller
chunks, which made distribution of the workload more manageable.

The three phases were:

\begin{itemize}
  \item \textbf{Phase 1}: Gossiping
  \item \textbf{Phase 2}: Leader Election
  \item \textbf{Phase 3}: Time Synchronization
\end{itemize}

We further divided these phases into concrete milestones.

\newpage

\section*{Gossiping}
\label{sec:gossiping}
In formulating our restraints for what constitutes a gossip protocol, we
used the Wikipedia
article\footnote{\url{https://en.wikipedia.org/wiki/Gossip_protocol}}
as an orientation. Thus, we define a gossip protocol as one that
satisifies the following conditions:

\begin{itemize}
  \item The core of the protocol involves periodic, pairwise
    interactions
  \item The information exchanged during these interactions is of
    bounded size
  \item When nodes interact, the state of at least one node changes to
    reflect the state of the other
  \item Reliable communication is not assumed
  \item The frequency of the interactions is low compared to typical
    message latencies so that the protocol costs are negligible
  \item There is some form of randomness in the peer selection. Peers
    might be selected from the full set of nodes or from a smaller set
    of neighbours
\end{itemize}

\subsection*{Protocol description}
\label{sub:protocol_gossiping}

\subsubsection*{Neighbour management}
\label{ssub:Neighbour_management}
In order to be able to gossip to random neighbours, nodes need to
maintain a list of these neighbours. Thus, nodes need to announce
themselves in a broadcast fashion so that other nodes can notice them.
Because we are dealing with non-static networks, nodes will also have to
periodically re-announce themselves and also need to remove nodes they
haven't heard from in a while from their neighbour tables.

\subsubsection*{Information exchange}
\label{ssub:Information_exchange}
Nodes periodically choose a random neighbour to gossip to. Most of the
specifics of this should be left to the application, as the necessary
frequency of interactions can vary strongly from application to
application. Instead, the gossiping implementation should focus solely
on providing functions to select neighbours and to disseminate the
information specified by the application.

For the sake of flexibility, the gossiping implementation should also
provide a way to select neighbours in a way that is not, or at least not
completely, random. Examples include selecting a node from a subset of
nodes filtered by a certain metric or, in some cases, directly selecting
a specific single node.

\subsection*{Implementation}
\label{sub:implementation_gossiping}

\subsubsection*{Announcement}
\label{ssub:Announcement}
After initialization, nodes will periodically call
\lstinline!gossip_announce()! in order to announce their presence to
their neighbours:

\begin{lstlisting}
int gossip_announce(void) {
    char msg_buffer[strlen(PREAMBLE) + strlen(ANNOUNCE) + 1];
    sprintf(msg_buffer, "%s%s", PREAMBLE, ANNOUNCE);
    return gossip_send(NULL, msg_buffer, strlen(msg_buffer));
}
\end{lstlisting}

Gossip messages in our implementation are always prefixed with a number
of strings that specify their purpose. The preamble sigifies that the
message is part of the gossip protocol (only messages carrying the
gossip preamble are processed by the gossip implementation. If
applications want to specifiy their own messages that do not use the
gossiping infrastructure, they simply need to drop this preamble). The
\lstinline!ANNOUNCE! string signifies that the message is an
announcement.

\lstinline!gossip_send()! takes care of low-level communications by
handing the message over to the transceiver thread.

\subsubsection*{Message handling}
\label{ssub:Message_handling}
The gossip message handler differentiates the various types of messages
and acts accordingly. It also offers an interface for applications to
define their own mesage handlers. Application messages are marked with
the \lstinline!MSG! prefix and are handed over to the application
message handler by the gossip message handler.

Upon reception of an \lstinline!ANNOUNCE! message, a node immediately
replies with an \lstinline!ANNOUNCE! of its own. This helps newly
joining nodes quickly assemble a neighbour table of their vicinity.

Further message handler functions will be explained later in the text at
the appropriate points.

\subsubsection*{Neighbour table}
\label{ssub:neighbour_table}
The neighbour table is a linked list that keeps information on all nodes
that have recently been heard from. It offers a number of functions to
retrieve and manipulate data. An entry consists of a node (represented
by its UID) and a timestamp of the last message received from this node.

Upon reception of any kind of gossip message, the message handler
updates the neighbour table. The sender of the message is either added
to the table or, if the entry already exists, its timestamp is reset. 

Nodes periodically call \lstinline!gossip_cleanup()! in order to remove
outdated entries from the neighbour table:

\newpage

\begin{lstlisting}
void gossip_cleanup(void) {
    gossip_node_t *node = 0;
    item_t *cur = list_get_head(neighbours);
    timex_t now;
    vtimer_now(&now);
    while (cur) {
        node = (gossip_node_t*) list_get_value(cur);
        if (now.seconds - node->last_recv > CLEANUP_THRESHOLD) {
            if (gossip_on_remove_neighbour_handler) {
                if (gossip_on_remove_neighbour_handler(node)) {
                    DEBUG("D: forgetting about node %d by handlers choice\n", node->id);
                    list_remove_item(neighbours, cur);
                } else {
                    DEBUG("D: keeping node %d by handlers choice\n", node->id);
                }
            } else {
                DEBUG("D: forgetting about node %d\n", node->id);
                list_remove_item(neighbours, cur);
            }
        } else {
            DEBUG("D: will forget %i in %lu seconds\n", node->id,
                (CLEANUP_THRESHOLD - now.seconds + node->last_recv));
        }
        cur = list_get_next(cur);
    }
}
\end{lstlisting}

\lstinline!gossip_cleanup()! iterates through the neighbour list and
checks every entry's timestamp. If the timestamp is older than
\lstinline!CLEANUP_THRESHOLD! (default: 10 seconds), then a removal
process is initiated. The gossip framework allows the application to
register an \lstinline!on_remove_neighbour_handler! that is called at
this point if it exists. This grants the application two capabilities:
It may prevent the cleanup function from removing an outdated node if it
meets certain other requirements (\lstinline!cleanup! only removes the
node if the \lstinline!on_remove_handler! allows it) and it may initiate
further actions on the node before it is removed (finalization). Once
the \lstinline!on_remove_handler! has been called and removal is
allowed, the entry is removed from the neighbour list.

The neighbour list should also offer a number of functions to select
neighbours to gossip to. Currently, the only functions implemented are
selecting by random and selecting the neighbour with the oldest
timestamp, as these were sufficient for the applications we implemented.
Future extensions should include an interface for applications to define
their own neighbour selection strategies.

\section*{Leader election}
\label{sec:Leader_election}
Once again taking the
Wikipedia\footnote{\url{https://en.wikipedia.org/wiki/Leader_election}}
article as a starting point, we define leader election as the process of
designating a single node as the organizer of some task that is to be
distributed among several nodes.  Before the task is begun, all nodes
are either unaware which node will serve as the leader of the task, or
unable to communicate with the current leader. After a leader election
has been run, however, each node recognizes a particular, unique node as
the leader -- provided the network has not been partitioned in the
meantime.

\subsection*{Protocol description}
\label{sub:protocol_leader_election}

\subsubsection*{The ``greedy`` strategy}
\label{ssub:greedy_leader_election}
Since we are dealing with potentially unstable networks prone to packet
loss and (temporary) partitioning, we decided on a leader election
scheme that strives to elect the locally optimal leader. This means that
upon initiating a leader election, each node will start by electing
itself as the leader and gossiping its ``candidacy`` to its neighbours.
When a node receives a leader election message containing a candidate,
it compares this candidate to the candidate it currently considers to be
the leader. If the new candidate is ``better`` than the current one
(according to the leader election metric that is currently in place --
see below), it immediately assumes that candidate as its new leader. If
the new candidate is ``worse`` than the current one it immediately
replies with its own leader. This approach -- basic gossiping combined
with immediate, direct responses -- ensures that a leader is rapidly
agreed upon.

\subsubsection*{Metrics for leader election}
\label{ssub:leader_election_metrics}
Since in most networks, the nodes will be more or less identical, some
method is needed in order to break the symmetry among them. For an
application that simply needs one node to be the leader without placing
any specific restraints on it, we can simply use the nodes' unique IDs
and elect the node with the highest ID. However, some applications may
want to elect a node with specific qualities -- the best connected node,
the node with the highest throughput, the node closest to a certain
location, the node with the right environment parameters etc. Thus, the
leader election should ideally provide an interface for applications to
define their own metrics by which a leader is elected.

\newpage

\subsubsection*{Partitioning problem}
\label{ssub:partitioning_problem}
As stated above, we are dealing with potentially unstable networks prone
to packet loss and partitioning. Therefore, we need to weaken the
original restraints somewhat such that during leader election, each node
strives to elect the optimal leader within its connected partition of
a potentially larger network. Since a partitioned network can be viewed
as a set of several smaller, unconnected networks for all intents and
purposes, it makes sense for these subnetworks to elect their own
leaders as long as they remain partitioned. By periodically
re-initiating the leader election, partitions can agree on a common
leader on the event of their reunion.

\subsection*{Implementation}
\label{sub:implementation_leader_election}

\subsubsection*{Initial leader election}
\label{ssub:initial_leader_election}
After each node has finished initialization, announced itself to its
neighbours and built a neighbour table, it initiates a leader election
and tries to vote for itself:

\begin{lstlisting}
int leader_init(){
    char msg_buffer[strlen(PREAMBLE) + strlen(MSG) + strlen(LE) + UID_LEN + ROUND_LEN];
    gossip_node_t* node;

    node = gossip_get_neighbour(RANDOM);
    if(!node){
        WARN("W: no non-leader neighbours, election init failed.\n");
        return 1;
    }

    leader_set_leader( gossip_id );

    DEBUG("D: initial leader: %d\n",leader);
    DEBUG("D: round: %i\n", election_round);
    sprintf(msg_buffer, "%s%s%s%0" ROUND_LEN_STR "i%0" UID_LEN_STR "i",
                PREAMBLE, MSG, LE, election_round, leader);

    return gossip_send(node, msg_buffer, strlen(msg_buffer));
}
\end{lstlisting}

\newpage

If a node receives a leader election message, it checks its contents to
decide how it should act on it:

\begin{lstlisting}
void leader_handle_msg(void* msg_text, size_t size, uint16_t src){

    strncpy( round_buffer, (char*)msg_text+strlen(LE) , sizeof(round_buffer) );
    round = atol(round_buffer);

    // a new election round, invalidate leader and elect the next one
    if(round > election_round) {
        DEBUG("D: got new election round %i (was %i)\n",round,election_round);
        election_round = round;
        leader_init();
        free(msg_buffer);
        return;
    }

    // got leader from an old round, inform sending node
    if(round < election_round) {
        sprintf(msg_buffer, "%s%s%s%0" ROUND_LEN_STR "i%0" UID_LEN_STR "i",
                    PREAMBLE, MSG, LE, election_round, leader);
        node = gossip_find_node_by_id(src);
        gossip_send(node, msg_buffer, strlen(msg_buffer));
        free(msg_buffer);
        return;
    }

    received_leader = atol((char*)msg_text+strlen(LE)+UID_LEN);

    /* use MAX_UID as ACK identifier */
    if(received_leader == MAX_UID){
        free(msg_buffer);
        return;
    }

    if(received_leader < leader ){
        sprintf(msg_buffer, "%s%s%s%0" ROUND_LEN_STR "i%0" UID_LEN_STR "i",
                    PREAMBLE, MSG, LE, round, leader);
    }

    // update leader if we receive a better candidate
    if(received_leader >= leader ){
        leader_set_leader(received_leader);
        sprintf(msg_buffer, "%s%s%s%0" ROUND_LEN_STR "i%0" UID_LEN_STR "i",
                    PREAMBLE, MSG, LE, round, MAX_UID);
    }

    node = gossip_find_node_by_id(src);
    gossip_send(node, msg_buffer, strlen(msg_buffer));

}
\end{lstlisting}

We can see the logic from the protocol description implemented here --
the node checks whether the proposed candidate is better or worse than
its current leader and acts accordingly.

The above listing also introduces the concept of leader election rounds,
which is described in detail below.

\subsubsection*{Leader election rounds}
\label{ssub:leader_election_rounds}
Whenever we lose contact to the leader, we have to assume that the
leader has failed, which means that we need to elect a new one. The
easiest way to immediately recognize this loss of contact is to define
an \lstinline!on_remove_neighbour_handler! (see above) that triggers
upon cleanup of the neighbour table. If the node that is about to be
removed is the current leader, we trigger a new leader election round.
This means that we initiate a new leader election just like before, but
with an increased round counter. The round counter is always included in
leader election messages and checked by the leader election message
handler (see above). If a node receives a leader election message
containing a counter that is higher than its own counter, it knows that
a new round of leader elections has been initiated and discards its
current leader as outdated. If the received round counter is equal to
the current round counter, everything proceeds as normal, and if it is
lower, the sending node is immediately informed that a new round has
already been started. This helps nodes keep up to date with the events
in the network and to know whether they should act upon a leader
election message.

\section*{Time synchronization}
\label{sec:Time synchronization}
Time synchronization is an important problem in the field of distributed
systems. Even when initially set accurately, real clocks will differ
after some amount of time due to clock drift, caused by clocks counting
time at slightly different rates. This problem obviously takes on more
complexity with a rising number of nodes participating in a network. The
simplest solution is always a centralized one, with a time server
dictating the system time to all network participants. Even though we
will be dealing mainly with decentralized systems, we can approximate
this solution by using our leader election scheme to elect a node that
will act as the time server.

\newpage

\subsection*{Protocol description}
\label{sub:protocol_time_synch}

Once a node is sure that it is currently the leader of its network, it
may initiate time synchronization. This means that it will choose
a neighbour at random and gossip its current timestamp to that node.
Upon receiving this timestamp, the node notes its own timestamp and
pings the time server back. The time server in turn answers with another
timestamp. The receiving node once again notes the time. It now has four
timestamps, which it can use to calculate its own offset to the master
and adjust its own clock accordingly. Once a node has thus adjusted its
own clock, it may in turn start synchronizing other nodes in its
vicinity, thus ensuring that not only nodes directly connected to the
leader are synchronized. Synchronization should be initiated
periodically to counteract clock drift.

\subsection*{Implementation}
\label{sub:implementation_time_synchronization}

\subsubsection*{Problems}
\label{ssub:timesync_problems}
During the implementation, we encountered several problems. Chief among
these was the fact that it is not possible to set the hardware clock on
the MSB-A2 boards. Thus, to demonstrate our time synchronization proof
of concept, we needed to approach the concept in a different fashion. As
we wanted to demonstrate synchronization across the network by having
the nodes' LEDs blink in usion, we decided on the following workaround:
Nodes would blink their LEDs on every full second. Synchronization is
achieved by measuring the offset to the leader and adding it to the wait
time between blinks, thus ensuring that nodes blink at the same time as
the leader.

\newpage

\subsubsection*{Initialisation}
\label{ssub:timesync_initialisation}
We implement our solution by having the time server send out a time
synchronization message on the full second:

\begin{lstlisting}
int timesync_init() {

    node = gossip_get_neighbour(RANDOM);

    msg_buffer = malloc(strlen(PREAMBLE) + strlen(MSG) + strlen(TS) + strlen(SYNC) + UID_LEN + 8);

    sprintf(msg_buffer, "%s%s%s%s%0" UID_LEN_STR "i%08lu", PREAMBLE, MSG, TS, SYNC, (int) gossip_id,
            master_offset);

    /* timesync init and blink loop need to be synced locally, wait for usec=0 */
    rtc_time(&tiv);
    vtimer_usleep( (uint32_t)(( 1000*1000 - tiv.tv_usec ) * VTIMER_FACTOR ));

    gossip_send(node, msg_buffer, strlen(msg_buffer));

    rtc_time(&tiv);
    return 0;
}
\end{lstlisting}

If a node receives a \lstinline!SYNC! message, it checks whether it was
sent by the node it recognizes as the leader and, if this is the case,
records the received and the local timestamp and responds with
a \lstinline!DELAYREQ! message:

\begin{lstlisting}
if (!strncmp(rcv_buffer, SYNC, strlen(SYNC))) {

    if( leader_is_leader() ){
        // master does not want to update its time
        return;
    }
    t1_local = tiv.tv_usec;

    // If message comes from the leader (directly or indirectly),
    // record master and local timestamps and initiate ping-pong
    if (ts_src == leader_get_leader()) {

        t1_master = atoi(rcv_buffer + strlen(SYNC) + UID_LEN);
        rtc_time(&tiv);

        gossip_node_t* node = gossip_find_node_by_id(src);
        gossip_send(node, DELAY_REQ_BUFFER, strlen(DELAY_REQ_BUFFER));

    }
}
\end{lstlisting}

\newpage

When the time server receives a \lstinline!DELAYREQ! message, it replies
with a \lstinline!DELAYRESP! and another timestamp:

\begin{lstlisting}
else if (!strncmp(rcv_buffer, DELAYREQ, strlen(DELAYREQ))) {

    msg_buffer = malloc(strlen(PREAMBLE) + strlen(MSG) + strlen(TS) + strlen(DELAYRESP) + 8);

    sprintf(msg_buffer, "%s%s%s%s%08lu", PREAMBLE, MSG, TS, DELAYRESP, tiv.tv_usec);

    gossip_node_t* node = gossip_find_node_by_id(src);
    gossip_send(node, msg_buffer, strlen(msg_buffer));
}
\end{lstlisting}

Finally, upon receiving the \lstinline!DELAYRESP! message, the receiving
node can calculate its own offset:

\begin{lstlisting}
else if (!strncmp(rcv_buffer, DELAYRESP, strlen(DELAYRESP))) {

    t2_local = tiv.tv_usec;
    t2_master = atoi(rcv_buffer + strlen(DELAYRESP));

    // Calculate offset (half RTT + our local time at first arrival of sync msg) - really?
    rtt_local   = t2_local > t1_local ? t2_local - t1_local : (1000000 - t1_local) + t2_local;
    rtt_master  = t2_master > t1_master ? t2_master - t1_master : (1000000 - t1_master) + t2_master;

    /* average over both observed roundtrips and assuming both direction took the same time
     * divide by two to get the offset of master and local */
    tt = (rtt_local + rtt_master)/2/2;
    master_offset = (t1_local > tt ? t1_local - tt : (1000*1000) + t1_local - tt);

    new_precision = ABS( (t1_local - t2_local ) - (t2_master - t1_master) );

    timesync_set_trusted(1);

}
\end{lstlisting}

This offset is then applied to the node's own blink thread, bringing it
into synchronization with the leader. The node then sets its own
\lstinline!trusted! flag, indicating that it has been synchronized with
the time server and is ready to synchronize its own neighbours.

\newpage

\section*{Working on the project} % XXX need a better name for this section
\label{sec:working_on_project}
We decided very early on that we would divide our project into the three
phases described above. This allowed us to logically structure our work
and break it down into easily manageable chunks. The first week was
spent actually deciding what the second and third phase would be, i.e.
what applications we wanted to build on top of our gossiping platform.
Discarded ideas included aggregation of sensor information such as
temperature and humidity. However, we quickly decided on something that
we could actually demonstrate using just the LEDs on the board, as noted
in the project goals, for which leader election and time synchronization
seemed the best choices.

\subsubsection*{Work distribution}
\label{ssub:work_distribution}
After handing in our project proposal, we started work according to the
timeline we had set for ourselves. This meant formulating the protocol
for a phase, implementing it and then moving to the next phase. We
discussed the protocols in group meetings; we were always able to
finalize them after one meeting. Work on the implementation was then
distributed dynamically; using our protocol descriptions, we formulated
TODOs and priorities and then distributed these amongst ourselves. We
had both regular and irregular meetings, depending on how far along in
our timeline we were. Between meetings, we worked more or less
individually with electronic communications. The regular meetings served
to bring the other members up to date on one's own work and to discuss
problems. Irregular meetings were called when we encountered problems
that we wanted to tackle as a team and also served as brainstorming
sessions. As all of us also had other obligations during the semester
(work, other classes etc.), we also sometimes met in pairs, but took
care to communicate our choices to the missing member.

\subsubsection*{Problems}
\label{ssub:problems}
Obviously, a project never runs as smoothly as one envisions it when
formulating milestones, and part of the point of a college software
project is to learn how to deal with problems and setbacks in
a non-critical work environment. We encountered our fair share of these
problems but were always able to deal with them.

The bulk of our implementation was done on the native port of RIOT,
which we chose because it would allow us to develop on x86 and not spend
valuable development time continuously flashing hardware. It also
allowed us to simulate larger networks than we could have built using
the hardware available to us. The native port, however, came with its
own share of problems. It is a relatively new addition to the RIOT
project and therefore still has a few quirks and bugs. We communicated
a lot with Ludwig Ortmann, the RIOT team member mainly responsible for
the native port, during this time. For some bugs, he pointed us to
workarounds that allowed us to carry on with our work. Other bugs, both
those already known to the RIOT team and those discovered by us, were
fixed during the course of our project.

The switch from native port to real hardware, once our implementation
neared completion, was not exactly smooth. First of all, actually
getting the MSB-A2 boards we wanted to test on proved difficult as the
AG Technische Informatik doesn't have a lot of them and most were
already being used in other projects. After some brief and unsuccessful
experimentation with AVS-Extrem boards borrowed from the VIVE project,
we were lucky enough to get three MSB-A2 boards from the RIOT team.

Moving to real hardware meant that we now had to deal with the physical
reality embedded programmers face -- stack sizes were suddenly to small
and the whole range of physical layer problems such as packet loss and
collisions became significant. Thus, we spent a good deal of the time
after the switch mitigating these problems and adjusting our
implementation to conform to embedded reality. However, we were still
able to overcome all of these problems and deliver a working demo in
time for the final presentation.

\section*{Evaluation \& Conclusion}
\label{sec:evaluation_conclusion}
Seeing as we met all of the goals we had originally set for ourselves
and delivered a working demo that did what it was supposed to do, we
would say that our project was definitely a success and we are very
satisified with the results. However, not everything worked as
originally planned. Our biggest mistake was probably making the switch
to the physical platform far too late. If we had switched earlier, maybe
some time during the implementation of leader election, we would have
had more time to accustom ourselves to the idiosyncracies of the MSB-A2
board and the physical medium, which would have saved us a lot of time
rewriting code that worked on the native port but was useless on the
MSB-A2. This could have prevented some stress during the last two weeks
before the final demonstration and would have made for more relaxed
development.

We also did not have enough time for the ``bonus`` goal we mentioned in
our original proposal -- encryption and security. However, this was
always an optimistic plan formulated for the event that everything went
smoother than expected and we found ourselves with free time on our
hands. Thus, we are not really disappointed that we didn't reach this
point, although it would have been very interesting.

In conclusion, we learnt a lot about the RIOT platform and the
limitations of embedded programming, as well as the intricate evils of
race conditions (there were a lot of those) and how to deal with them.
We hope that our project will be integrated into the RIOT/projects
repository as has been signaled by the RIOT team, thus making our
project something we made not only for ourselves but also for other RIOT
developers to build upon.

\end{document}

\end{document}
